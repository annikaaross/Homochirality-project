{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "History_reader.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/annikaaross/Homochirality-project/blob/master/History_reader.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "duYO-tSssN_Z",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title **Mount drive**\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)\n",
        "wdir = '/content/drive/Shared drives/Homochirality'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wfmf007asW-c",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "# @title **Imports**\n",
        "import numpy as np\n",
        "import copy\n",
        "from google.colab import widgets, output\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import time\n",
        "import datetime\n",
        "import uuid\n",
        "from IPython.display import display, Markdown, clear_output\n",
        "import ipywidgets\n",
        "import glob\n",
        "import csv\n",
        "\n",
        "\n",
        "parameters = [\"BASE_BOND_BREAK_PROBABILITY\",\"HOMOCHIRAL_BREAK_FACTOR\",\"HOMOCHIRAL_NEIGHBOR_IMPROV_FACTOR\",\"LENGTH_FACTOR\",\"N\",\"LAMBDA\",\"HOMOCHIRAL_BREAK_FACTOR_LEFT\",\"HOMOCHIRAL_BREAK_FACTOR_RIGHT\",\"HOMOCHIRAL_NEIGHBOR_IMPROV_FACTOR_LEFT\",\"HOMOCHIRAL_NEIGHBOR_IMPROV_FACTOR_RIGHT\",\"POOF_CHANCE\",\"BOND_PROB\",\"POOL_SIZE\",\"iterations\",\"METHOD\",\"POISSON_FACTOR\",\"FUSION\"]\n",
        "statistics = [\"MaxLen\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0hSx43Hpg7W",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title **Helper functions**\n",
        "\n",
        "# A function to work out which column names are what \n",
        "def id_headers(info):\n",
        "  # Make a list to store the various categories\n",
        "  indep_vars = [] # parameters that change\n",
        "  constants = [] # parameters that don't change\n",
        "  measures = [] # data calculated in parsing\n",
        "  # Iterate through all the columns in info\n",
        "  for col in info:\n",
        "    # And get the ones that are parameters (are all upper-case)\n",
        "    if col.isupper():\n",
        "      # Find how many different values that parameter takes over the course of the run\n",
        "      n=len(info[col].unique())\n",
        "      # If it's more than one\n",
        "      if n > 1:\n",
        "        # Then the parameter varies and we want to store it in indep_vars.\n",
        "        indep_vars.append(col)\n",
        "      else: \n",
        "        # The parameter doesn't very and we want it in constants.\n",
        "        constants.append(col)\n",
        "    else:\n",
        "      # It's not a parameter\n",
        "      # Check if it's a \"bookkeeping\" column\n",
        "      if (col != \"Path\") and (col != \"Unnamed: 0\"):\n",
        "        # It's a calculated data point and we store it in measures\n",
        "        measures.append(col)\n",
        "  # Now we return the lists we've made.\n",
        "  return indep_vars, constants, measures\n",
        "\n",
        "def plots(runname):\n",
        "  # Get the run you want\n",
        "\n",
        "  d_file = f\"{wdir}/{folder.value}/{runname}_data.csv\"\n",
        "  p_file = f\"{wdir}/{folder.value}/{runname}_params.csv\"\n",
        "\n",
        "  # First get the stats we want from the datafile\n",
        "  data = pd.read_csv(d_file, engine='python')\n",
        "\n",
        "  # Then get the parameters\n",
        "  param_file = open(p_file,'r')\n",
        "  reader = csv.reader(param_file)\n",
        "  params = {rows[0]:rows[1] for rows in reader}\n",
        "  param_file.close()\n",
        "\n",
        "  # The plots\n",
        "\n",
        "  stats = data\n",
        "\n",
        "  iterations = data[\"Iteration\"].max()\n",
        "\n",
        "\n",
        "  plots = [\"Signed EE of Polymers by Iteration\",\"Proportion of Bond Types\",\n",
        "           \"Homochirality vs Length\",\n",
        "           \"Homochirality vs Age\",\n",
        "           \"Homochirality vs Length through Time\",\"Length histogram over time\",\n",
        "           \"Length by homochirality through age\",\"Age by homochirality through length\"]\n",
        "  tb = widgets.TabBar(plots)\n",
        "\n",
        "  with tb.output_to(\"Signed EE of Polymers by Iteration\", select=True):\n",
        "    tb.clear_tab()\n",
        "    df = stats\n",
        "    counts = df.groupby(\"Iteration\")['Signed ee'].value_counts().reset_index(name='count')\n",
        "    fig = px.scatter(counts, x=\"Iteration\", y=\"Signed ee\", size='count')\n",
        "    fig.show()\n",
        "\n",
        "\n",
        "  with tb.output_to(\"Proportion of Bond Types\", select=False):\n",
        "    tb.clear_tab()\n",
        "\n",
        "    df = stats\n",
        "    lefts = df.groupby(\"Iteration\")[\"#LeftHomochiral\"].sum().rename(\"LL\")\n",
        "    rights = df.groupby(\"Iteration\")[\"#RightHomochiral\"].sum().rename(\"RR\")\n",
        "    total = (df.groupby(\"Iteration\")['Length'].sum() - df.groupby(\"Iteration\")['Length'].count()).rename(\"Total\")\n",
        "    bondcounts = pd.DataFrame([lefts, rights, total]).transpose()\n",
        "    bondcounts[\"LR\"] = bondcounts[\"Total\"] - bondcounts[\"RR\"] - bondcounts[\"LL\"]\n",
        "    bondcounts = bondcounts.apply(lambda x : x / bondcounts[\"Total\"])\n",
        "    \n",
        "    fig = go.Figure()\n",
        "    fig.add_trace(go.Scatter(y=bondcounts[\"LL\"],\n",
        "                        mode='lines',\n",
        "                        name='left homochiral'))\n",
        "    fig.add_trace(go.Scatter(y=bondcounts[\"RR\"],\n",
        "                        mode='lines',\n",
        "                        name='right homochiral'))\n",
        "    fig.add_trace(go.Scatter(y=bondcounts[\"LR\"],\n",
        "                        mode='lines', name='heterochiral'))\n",
        "    fig.update_layout(title='Proportion of LL, RR, and LR bonds by iteration',\n",
        "                    xaxis_title='Iteration',\n",
        "                    yaxis_title='Proportion')\n",
        "    fig.update_yaxes(range=[0, 1])\n",
        "\n",
        "    fig.show()\n",
        "\n",
        "  with tb.output_to(\"Homochirality vs Length through Time\", select=False):\n",
        "    tb.clear_tab()\n",
        "    df = stats\n",
        "    maxlen = max(df[\"Length\"])\n",
        "\n",
        "    fig = px.scatter(df, x=\"Length\", y=\"%Homochirality\",animation_frame=\"Iteration\",\n",
        "                    range_x=[-1,maxlen+1],range_y=[-0.01,1.2])\n",
        "    fig.show()\n",
        "\n",
        "  with tb.output_to(\"Homochirality vs Length\", select=False):\n",
        "    tb.clear_tab()\n",
        "    df = stats\n",
        "    df = df.groupby(\"Length\")['%Homochirality'].value_counts().reset_index(name='count')\n",
        "    fig = px.scatter(df, x=\"Length\",y=\"%Homochirality\",size='count')\n",
        "    fig.update_traces(marker=dict(line=dict(color='DarkSlateGrey')),\n",
        "                    selector=dict(mode='markers'))\n",
        "    fig.show()\n",
        "\n",
        "  with tb.output_to(\"Homochirality vs Age\", select=False):\n",
        "    tb.clear_tab()\n",
        "    df = stats\n",
        "    df = df.groupby(\"Age\")['%Homochirality'].value_counts().reset_index(name='count')\n",
        "    fig = px.scatter(df, x=\"Age\",y=\"%Homochirality\",size='count')\n",
        "    fig.update_traces(marker=dict(line=dict(color='DarkSlateGrey')),\n",
        "                    selector=dict(mode='markers'))\n",
        "    # This gets the mode of col b for each value of col a\n",
        "    modes = df.groupby(\"Age\")[\"%Homochirality\"].agg(lambda x:x.value_counts().index[0])\n",
        "    fig.add_trace(go.Scatter(y=modes, mode=\"markers\"))\n",
        "    fig.show()\n",
        "\n",
        "  with tb.output_to(\"Length by homochirality through age\", select = False):\n",
        "    tb.clear_tab()\n",
        "    df = stats\n",
        "    fig = px.scatter(df, x=\"Length\", y=\"%Homochirality\", animation_frame=\"Age\", hover_name=\"%Homochirality\", range_x=[1,maxlen+1])\n",
        "    fig.show()\n",
        "\n",
        "  with tb.output_to(\"Age by homochirality through length\", select = False):\n",
        "    tb.clear_tab()\n",
        "    df = stats\n",
        "    fig = px.scatter(df, x=\"Age\", y=\"%Homochirality\", animation_frame=\"Length\", hover_name=\"%Homochirality\", range_y=(0,1), range_x=[-1,iterations+1])\n",
        "    fig.show()\n",
        "\n",
        "  with tb.output_to(\"Length histogram over time\", select=False):\n",
        "    tb.clear_tab()\n",
        "    df = stats\n",
        "\n",
        "    # Just the polymers please\n",
        "    df = df[df[\"Length\"]>1]\n",
        "\n",
        "    # Find the largest count overall\n",
        "    count_iteration = df.groupby(\"Iteration\")[\"Length\"].value_counts()\n",
        "    biggest = max(count_iteration)\n",
        "\n",
        "    fig = px.histogram(df, x=\"Length\", animation_frame=\"Iteration\",range_x=(0,max(df[\"Length\"])),\n",
        "                        nbins=max(df[\"Length\"]))\n",
        "    fig.show()\n",
        "\n",
        "\n",
        "\n",
        "###############\n",
        "\n",
        "# Functions to calculate stats in data parsing\n",
        "\n",
        "def max_len(df):\n",
        "  return max(df[\"Length\"])\n",
        "\n",
        "def longest_chain(df):\n",
        "  try:\n",
        "    return df[\"Longest chain length\"].dropna().max()\n",
        "  except: \n",
        "    return None\n",
        "\n",
        "\n",
        "# steady state measurements\n",
        "\n",
        "# def get_steady_state(df,column,epsilon=0.01,nbins=10):\n",
        "#   of_interest = df[[column,\"Iteration\"]]\n",
        "#   # How many iterations were there?\n",
        "#   final = max(df[\"Iteration\"])+1\n",
        "#   # Get the mins for calculation ranges\n",
        "#   mins = list(range(0,final,final/nbins)) # should give 0,10,20,... for final=100 and nbins=10\n",
        "#   # A place to keep the calculated means\n",
        "#   means = []\n",
        "#   # Get the mean value of column for each calculation range\n",
        "#   for m in mins:\n",
        "#     area_of_interest = of_interest[of_interest[\"Iteration\"] >= m]\n",
        "#     means.append(area_of_interest[column].mean())\n",
        "\n",
        "def get_steady_state(pandas_series,epsilon=0.01,window_size=30, step=10):\n",
        "  # A place to keep the calculated means\n",
        "  means = []\n",
        "  stdevs = []\n",
        "  # Make a window\n",
        "  window = np.array([0,window_size])\n",
        "  # Put this in a loop\n",
        "  while window[1] <= len(pandas_series):\n",
        "    # Get all the data in the window\n",
        "    frame = pandas_series[window[0]:window[1]]\n",
        "    # Get the average and store it\n",
        "    means.append(frame.mean())\n",
        "    stdevs.append(frame.std())\n",
        "    # increment the window\n",
        "    window += step\n",
        "  # find the index at which all subsequent stdevs are less than epsilon\n",
        "  index = 0\n",
        "  while index < len(stdevs):\n",
        "    if all([sd < epsilon for sd in stdevs[index:]]):\n",
        "     return round(sum(means[index:])/len(means[index:]),3), index\n",
        "    else:\n",
        "      index += 1\n",
        "  return (None, None)\n",
        "\n",
        "def get_chirality_ratio(df,epsilon=0.01,window_size=30, step=10):\n",
        "  \"\"\" Suppose we want the steady state of the chirality ratio of a run. \"\"\"\n",
        "  # This makes a dataframe of the bond types in a run (from plots)\n",
        "  lefts = df.groupby(\"Iteration\")[\"#LeftHomochiral\"].sum().rename(\"LL\")\n",
        "  rights = df.groupby(\"Iteration\")[\"#RightHomochiral\"].sum().rename(\"RR\")\n",
        "  total = (df.groupby(\"Iteration\")['Length'].sum() - df.groupby(\"Iteration\")['Length'].count()).rename(\"Total\")\n",
        "  bondcounts = pd.DataFrame([lefts, rights, total]).transpose()\n",
        "  bondcounts[\"LR\"] = bondcounts[\"Total\"] - bondcounts[\"RR\"] - bondcounts[\"LL\"]\n",
        "  bondcounts = bondcounts.apply(lambda x : x / bondcounts[\"Total\"])\n",
        "\n",
        "  # Then get the steady states of the columns\n",
        "  steady_LL = get_steady_state(bondcounts[\"LL\"],epsilon=epsilon,window_size=window_size,step=step)\n",
        "  steady_RR = get_steady_state(bondcounts[\"RR\"],epsilon=epsilon,window_size=window_size,step=step)\n",
        "  steady_LR = get_steady_state(bondcounts[\"LR\"],epsilon=epsilon,window_size=window_size,step=step)\n",
        "  \n",
        "  # And return!\n",
        "  return steady_LL, steady_RR, steady_LR\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aX0HxB3Ecyt0",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "# @title **Import data**\n",
        "\n",
        "# Get folder name and batch name\n",
        "folder = ipywidgets.Text(description=\"subfolder:\",placeholder=\"enter subfolder name\")\n",
        "batch = ipywidgets.Text(description=\"batch:\",placeholder=\"enter batch name\")\n",
        "# Checkbox for if we wanna force a reparse\n",
        "reparse = ipywidgets.Checkbox(description=\"Force reparse\",value=False)\n",
        "# Text and int bar widgets for the progress bar\n",
        "status_text = ipywidgets.Output()\n",
        "progress_bar = ipywidgets.FloatProgress(min=0, max=100) \n",
        "# Make a name for the data to go into\n",
        "info = None\n",
        "# Make a spot for storing out the variables that change\n",
        "changers = None\n",
        "\n",
        "def get_data(b):\n",
        "  progress_bar.value = 0\n",
        "  global info\n",
        "  batch_path = f\"{wdir}/{folder.value}/{batch.value}\"\n",
        "  # Do we want to force a re-parse?\n",
        "  if not reparse.value:\n",
        "    try:\n",
        "      with status_text:\n",
        "        clear_output()\n",
        "        print(\"loading info\")\n",
        "      info = pd.read_csv(f\"{batch_path}_info.csv\")\n",
        "    except FileNotFoundError:\n",
        "      # parse\n",
        "      info = parse(batch_path)\n",
        "      # export\n",
        "      info.to_csv(f\"{batch_path}_info.csv\")\n",
        "  else:\n",
        "    # parse\n",
        "    info = parse(batch_path)\n",
        "    # export\n",
        "    info.to_csv(f\"{batch_path}_info.csv\")\n",
        "  # Say \"I'm done!\"\n",
        "  with status_text:\n",
        "    clear_output()\n",
        "    print(\"ok done\")\n",
        "  progress_bar.value = 100\n",
        "  for col in info:\n",
        "    if col.isupper():\n",
        "      print(f\"{col}: {info[col].unique()}\")\n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "  \n",
        "\n",
        "def parse(path):\n",
        "  # Prep the feedback\n",
        "  with status_text:\n",
        "    clear_output()\n",
        "    print(\"parsing info\")\n",
        "\n",
        "  # Get all the filenames under that batchname\n",
        "  params_filenames = []\n",
        "  data_filenames = [] \n",
        "  for filename in glob.glob(f\"{path}_*.csv\"):\n",
        "    if filename[-10:-4] == \"params\":\n",
        "      params_filenames.append(filename)\n",
        "    elif filename[-8:-4] == \"data\":\n",
        "      data_filenames.append(filename)\n",
        "\n",
        "  # Are there even any filenames? Let's not try to parse something that doesn't exist.\n",
        "    if len(data_filenames) == 0:\n",
        "      raise FileNotFoundError(\"Batch not found.\")\n",
        "\n",
        "  # Get the amount to increment the progress bar after each file\n",
        "  increment = 1/len(data_filenames) * 100\n",
        "\n",
        "  # Sort the filenames lists so they'll definitely sync\n",
        "  params_filenames.sort()\n",
        "  data_filenames.sort()\n",
        "\n",
        "  info_list = []\n",
        "  for p_file, d_file in zip(params_filenames,data_filenames):\n",
        "\n",
        "    # First step is getting the general path for this run!\n",
        "    run_path = d_file[:-9]\n",
        "\n",
        "    # First get the stats we want from the datafile\n",
        "    data = pd.read_csv(d_file, engine='python')\n",
        "    # Get the steady-states of the chiralities\n",
        "    steadies = get_chirality_ratio(data,epsilon=0.05)\n",
        "    stats = {\"MaxLen\":max_len(data),\n",
        "             \"LongestChain\":longest_chain(data),\n",
        "             \"SteadyLL\":steadies[0][0],\n",
        "             \"SteadyRR\":steadies[1][0],\n",
        "             \"SteadyLR\":steadies[2][0]}\n",
        "\n",
        "    # Then get the parameters\n",
        "    params = open(p_file,'r')\n",
        "    reader = csv.reader(params)\n",
        "    param_dict = {rows[0]:rows[1] for rows in reader}\n",
        "    params.close()\n",
        "\n",
        "    # Merge the parameters and the stats into a single dictionary\n",
        "    info_row = {\"Path\":run_path,**param_dict,**stats}\n",
        "    \n",
        "    # Store the row\n",
        "    info_list.append(info_row)\n",
        "\n",
        "    # Last step is incrementing the progress bar!\n",
        "    progress_bar.value += increment\n",
        "\n",
        "  # Turn this list into a DataFrame and return it\n",
        "  return pd.DataFrame(info_list)\n",
        "\n",
        "\n",
        "with status_text:\n",
        "  clear_output()\n",
        "progress_bar.value = 0\n",
        "loc_box = ipywidgets.VBox([folder,batch])\n",
        "display(loc_box)\n",
        "# Button for running the parsing stuff\n",
        "parse_button = ipywidgets.Button(description=\"Get data\")\n",
        "parse_button.on_click(get_data)\n",
        "display(reparse)\n",
        "display(parse_button)\n",
        "# Box for progress bars!\n",
        "progress = ipywidgets.VBox([status_text,progress_bar])\n",
        "display(progress)\n",
        "\n",
        "\n",
        "\n",
        " \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MZQU5JYSvN5",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title **Boxplot**\n",
        "# First check if info has been imported\n",
        "if not isinstance(info,pd.DataFrame):\n",
        "  print(\"Please import your batch, then re-run this cell.\")\n",
        "\n",
        "else:\n",
        "  # An import to allow clearing the output down the line\n",
        "  import IPython.display\n",
        "\n",
        "\n",
        "  def make_boxplot(b):\n",
        "    # Make the boxplot using the values selected in widgets\n",
        "    fig = px.box(info, \n",
        "                 x=boxplot_groups.value,\n",
        "                 y=boxplot_measures.value,\n",
        "                 color=boxplot_colors.value,\n",
        "                 hover_data=[\"Path\"])\n",
        "    fig.show()\n",
        "\n",
        "\n",
        "  def clear(b):\n",
        "    # Deletes the plots it's already made\n",
        "    IPython.display.clear_output(wait=True)\n",
        "    display(boxplot_container)\n",
        "\n",
        "\n",
        "  # Now we're cooking with gas.\n",
        "  # Run id_headers to get the varying and static parameters\n",
        "  # and the measured stats\n",
        "  vars, constants, measures = id_headers(info)\n",
        "\n",
        "  # Widget making and handling\n",
        "  # Dropdown menus\n",
        "  boxplot_groups = ipywidgets.Dropdown(options=vars, description=\"group\")\n",
        "  boxplot_colors = ipywidgets.Dropdown(options=[None]+vars, description=\"color\")\n",
        "  boxplot_measures = ipywidgets.Dropdown(options=measures, description=\"stat\")\n",
        "  # Buttons\n",
        "  boxplot_button = ipywidgets.Button(description=\"plot\")\n",
        "  boxplot_clear_button = ipywidgets.Button(description=\"clear output\")\n",
        "  # Layout\n",
        "  boxplot_selectors = ipywidgets.VBox([boxplot_groups,boxplot_colors,boxplot_measures])\n",
        "  boxplot_container = ipywidgets.VBox([boxplot_selectors,ipywidgets.HBox([boxplot_button,boxplot_clear_button])])\n",
        "  # Button behavior\n",
        "  boxplot_button.on_click(make_boxplot)\n",
        "  boxplot_clear_button.on_click(clear)\n",
        "  # Show the widgets\n",
        "  display(boxplot_container)\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0r-dzWBJtzN",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title **Plot an individual run**\n",
        "\n",
        "# First check if info has been imported\n",
        "if not isinstance(info,pd.DataFrame):\n",
        "  print(\"Please import your batch, then re-run this cell.\")\n",
        "\n",
        "else:\n",
        "\n",
        "  # Definitions\n",
        "\n",
        "  # Get just the filename part of the Paths series\n",
        "  def filenames_from_paths(df):\n",
        "    trim = lambda x : x[len(wdir)+len(folder.value)+2:]\n",
        "    return list(map(trim,list(df[\"Path\"])))\n",
        "\n",
        "  # Get the filenames of the runs that match the selected var values\n",
        "  def get_values(b):\n",
        "    value = lambda x : x.value\n",
        "    selected_values = list(map(value, var_widgets))\n",
        "    df = info\n",
        "    for n in range(len(vars)):\n",
        "      df = df[df[vars[n]]==selected_values[n]]\n",
        "    file_selector.options = filenames_from_paths(df)\n",
        "\n",
        "\n",
        "  def clear(b):\n",
        "      # Deletes the plots it's already made\n",
        "      clear_output(wait=True)\n",
        "      display(boxplot_container)\n",
        "\n",
        "  # Show the plots of the the selected run\n",
        "  def plot(b):\n",
        "    clear_output(wait=True)\n",
        "    display(selector_box)\n",
        "    plots(file_selector.value)\n",
        "\n",
        "  # Main\n",
        "\n",
        "  # Here's a list of the filenames you can pick.\n",
        "  filenames = filenames_from_paths(info)\n",
        "\n",
        "  # Widgets\n",
        "  button = ipywidgets.Button(description=\"Update file list\")\n",
        "  out = ipywidgets.Output()\n",
        "  file_selector = ipywidgets.Select(options=filenames,description=\"Select file:\")\n",
        "  plot_button = ipywidgets.Button(description=\"Plot this run\")\n",
        "\n",
        "  # Run id_headers to get the varying and static parameters\n",
        "  # and the measured stats\n",
        "  vars, constants, measures = id_headers(info)\n",
        "  var_vals = []\n",
        "  var_widgets = []\n",
        "\n",
        "  # Now we need the values that each of the vars takes\n",
        "  for var in vars:\n",
        "    # Get the unique values that are taken by var\n",
        "    uniques = info[var].unique()\n",
        "    uniques.sort()\n",
        "    var_vals.append(uniques)\n",
        "\n",
        "  # Make a slider widget for each variable\n",
        "  for n in range(len(vars)):\n",
        "    var_widgets.append(ipywidgets.SelectionSlider(options=var_vals[n],description=vars[n]))\n",
        "      \n",
        "  # What the buttons do\n",
        "  button.on_click(get_values)\n",
        "  plot_button.on_click(plot)\n",
        "\n",
        "  # Widget layouts\n",
        "  selector_box = ipywidgets.VBox([ipywidgets.HBox([ipywidgets.VBox(var_widgets),file_selector]),\n",
        "                                  ipywidgets.HBox([button,plot_button])])\n",
        "  # Show the widgets\n",
        "  display(selector_box)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}